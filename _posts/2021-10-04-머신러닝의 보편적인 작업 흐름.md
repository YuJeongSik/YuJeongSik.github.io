#머신러닝의 보편적인 작업 흐름

## 들어가기에 앞서(윤리적 문제)
기술은 결코 중립일 수 없습니다. 만약 여러분의 연구가 세상에 영향을 미친다면, 이 영향은 도덕적인 방향을 가집니다: 기술적인 선택 또한 윤리적 선택입니다. 당신의 작품이 뒷받침하기를 바라는 가치에 대해 항상 숙고하세요.

자 이제 본론으로 들어가봅시다. 머신러닝의 보편적 작업흐름은 크게 세 부분으로 구성된다.

* 과제 정의: 문제 영역과 고객이 질문한 내용을 뒷받침하는 비즈니스 논리를 이해합니다. 데이터 집합을 수집하고 데이터가 나타내는 바를 파악한 후 작업에서 성공을 측정하는 방법을 선택합니다.


* 모델 개발: 머신러닝 모델에서 데이터를 처리할 수 있도록 준비하고, 모델 평가 프로토콜과 이길 수 있는 간단한 기준선을 선택한 다음, 오버핏할 수 있는 일반화 능력을 갖춘 첫 번째 모델을 교육한 다음, 최대한의 일반화 성능을 달성할 때까지 모델을 정규화하고 조정합니다.


* 모델 배치: 이해 관계자에게 작업물을 전달하고, 웹 서버, 모바일 앱, 웹 페이지 또는 임베디드 장치로 모델을 전달하며, 야생에서의 모델 성능을 모니터링하고, 차세대 모델 구축에 필요한 데이터를 수집하기 시작합니다.

## 과제정의
내가 하는 일의 맥락을 깊이 이해하지 않으면 좋은 일을 할 수 없습니다. 당신의 고객은 왜 이 문제를 해결하려고 합니까? 모델 사용 방법, 고객의 비즈니스 프로세스에 적합한 방법 등 솔루션으로부터 어떤 가치를 얻을 수 있습니까? 어떤 종류의 데이터를 사용할 수 있거나 수집할 수 있습니까? 비즈니스 문제에 매핑할 수 있는 기계 학습 과제는 무엇입니까?
이러한 질문들에 대해 우리는 생각을 해볼 필요성이 있습니다

### 틀을 만들기
기계 학습 문제를 구체화하려면 일반적으로 이해관계자들과의 많은 상세한 논의가 필요합니다. 그리고 우리가 항상 생각하고 있어야할 것들이 있습니다.

* 어떤 데이터가 입력됩니까? 당신은 무엇을 예측하려고 하는 건가요? 예를 들어 영화 리뷰와 정서 주석이 모두 있는 경우에만 영화 리뷰의 감정을 분류하는 방법을 배울 수 있습니다. 이와 같이, 우리가 사용할 수 있는 데이터는 매우 제한적입니다. 대부분의 경우 사용자가 직접 새 데이터셋을 수집하고 주석을 달아야 합니다.


* 어떤 유형의 머신러닝 과제를 직면하고 계십니까? 경우에 따라 머신러닝이 데이터를 이해하는 가장 좋은 방법이 아닐 수도 있으며, 오래된 학교 통계 분석과 같은 다른 방법을 사용해야 합니다.


* 기존 솔루션은 어떤 모습입니까? 어떤 시스템이 이미 구축되어 있는지, 어떻게 작동하는지 확실히 이해해야 합니다.


* 처리해야 할 특별한 제약이 있나요? 당신은 당신의 작품에 들어맞을 전체 맥락을 이해해야 합니다.

위의 것들을 항상 생각하고 있다면 이제 다음 단계로 넘어가봅시다. 일단 조사를 마쳤으면, 여러분은 여러분의 입력이 무엇일지, 여러분의 목표가 무엇인지, 그리고 문제가 어떤 종류의 기계 학습 과제로 매핑되는지 알아야 합니다. 이 단계에서 여러분이 하는 가설에 아래와 같은 것들을 유의해야합니다.

* 입력이 주어지면 목표값을 예측할 수 있다는 가설을 세웁니다.

* 사용할 수 있는 데이터(또는 곧 수집할 데이터)가 입력과 목표값 간의 관계를 학습하는 데 충분한 정보를 제공한다는 가설을 세웁니다.

### 데이터셋 수집하기
작업의 특성을 이해하고 입력과 대상이 무엇인지 알게 되면 대부분의 머신러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용이 많이 드는 부분인 데이터를 수집할 때입니다.


모델의 일반화 성능은 거의 전적으로 학습된 데이터의 속성(데이터 포인트 수, 레이블의 안정성, 기능 품질)에서 비롯됩니다. 프로젝트에 시간을 더 투자할 경우 모델을 수정하는 것보다는 더 많은 데이터를 수집하는 것이 가장 효과적인 방법입니다.

지도 학습을 수행하는 경우 입력(예: 이미지)을 수집한 후에는 입력(예: 이미지 태그)에 대한 주석(예: 모델이 예측할 목표)이 필요합니다. 음악 추천 작업이나 클릭률 예측 작업의 경우 주석을 자동으로 검색할 수 있습니다. 하지만 종종 데이터에 주석을 직접 달아야 합니다. 이것은 힘든 과정입니다.

데이터에 레이블을 붙이기로 결정한 경우 주석을 기록하는 데 어떤 소프트웨어를 사용할지 생각해봐야 합니다. 당신이 직접 그 소프트웨어를 개발해야 할 수도 있습니다. 생산적인 데이터—주석 소프트웨어는 많은 시간을 절약할 수 있으므로 프로젝트 초기에 투자할 가치가 있습니다.

####비대표 데이터 주의

머신러닝 모델은 이전에 본 것과 비슷한 입력만을 이해할 수 있습니다. 따라서 교육에 사용되는 데이터가 생산 데이터를 대표해야 합니다. 데이터를 수집할때 가장 근본이 되는 문제중 하나입니다.

가능하면 모델이 사용될 환경에서 직접 데이터를 수집합니다. 영화 감상 분류 모델은 옐프 레스토랑 리뷰나 트위터 상태 업데이트가 아닌 새로운 IMDB 리뷰에 사용되어야 합니다. 트윗의 감성을 평가하려면 프로덕션에서 예상하는 사용자 집합과 유사한 사용자로부터 실제 트윗을 수집하고 주석을 다는 것부터 시작해야합니다. 프로덕션 데이터에 대한 교육이 가능하지 않다면 교육 데이터와 프로덕션 데이터가 어떻게 다른지 완전히 이해하고 이러한 차이를 적극적으로 수정해야 합니다.

당신이 알아야 할 관련 현상은 개념 드리프트입니다. 거의 모든 실제 문제, 특히 사용자 생성 데이터를 다루는 문제에서 개념의 표류를 경험할 수 있습니다. 개념 드리프트는 시간이 지남에 따라 생산 데이터의 속성이 변경되어 모델 정확도가 점차 저하될 때 발생합니다. 2013년에 훈련받은 음악 추천 엔진은 오늘날 그다지 효과적이지 않을 수 있습니다. 마찬가지로, 작업한 IMDB 데이터 집합도 일괄적으로 수집되었으며, 이 데이터 집합으로 훈련된 모델은 시간이 지남에 따라 어휘, 표현 및 영화 장르가 발전함에 따라 2012년의 리뷰와 비교하여 2020년의 리뷰에서 좋은 성능을 발휘하지 못할 수 있습니다. 개념 표류는 신용 카드 사기 탐지와 같은 적대적 맥락에서 특히 극심하며, 사기 패턴은 실질적으로 매일 변합니다. 빠른 개념 드리프트를 처리하려면 지속적인 데이터 수집, 주석 및 모델 재교육이 필요합니다.

**정리하자면, 기계 학습은 훈련 데이터에 존재하는 패턴을 암기하는 데만 사용될 수 있다는 것을 꼭 기억해야합니다.** 전에 본 것만 알아볼 수 있습니다. 미래를 예측하기 위해 과거 데이터에 대해 훈련된 머신러닝을 사용하는 것은 미래가 과거와 같이 행동할 것이라는 가정을 하는 것이고 그것이 항상 사실은 아닙니다.

### 데이터 이해하기
데이터 세트를 블랙박스로 취급하는 것은 매우 나쁜 관행입니다. 모델을 교육하기 전에 데이터를 탐색하고 시각화하여 예측 가능한 요소에 대한 통찰력을 얻고(기능 엔지니어링에 정보를 제공) 잠재적인 문제를 선별해야 합니다.

* 데이터에 이미지 또는 자연어 텍스트가 포함되어 있는 경우 몇 가지 샘플(및 해당 레이블)을 직접 살펴봐야합니다

* 데이터에 숫자 형상이 포함되어 있는 경우 형상 값의 히스토그램을 그래프로 표시하여 사용된 값의 범위와 다양한 값의 빈도를 파악하는 것이 좋습니다.

* 데이터에 위치 정보가 포함된 경우 지도에 표시합니다. 뚜렷한 패턴이 있나요?

* 일부 샘플이 일부 기능에 대한 결측값이 있습니까? 이 경우 데이터를 준비할 때 이 문제를 해결해야 합니다.

* 분류 문제인 경우 데이터에 있는 각 클래스의 인스턴스 수를 인쇄합니다. 클래스가 대략적으로 동등하게 표현됩니까? 그렇지 않다면 이 불균형을 고려해야 합니다.

* 타겟 누수 여부: 운영 환경에서 제공되지 않을 수 있는 타겟에 대한 정보를 제공하는 기능이 데이터에 있는지 확인합니다.

### 올바른 특징을 선택하기
무언가를 통제하기 위해서는 그것을 관찰할 수 있어야 합니다. 프로젝트에서 성공을 거두려면 먼저 성공의 의미, 즉 정확성을 정의해야 합니다. 성공을 위한 여러분의 지표는 프로젝트 전반에 걸쳐 여러분이 하게 될 모든 기술적 선택을 안내할 것입니다. 고객의 비즈니스 성공과 같은 보다 높은 수준의 목표에 직접적으로 부합해야 합니다.

## 모델 개발하기
진행 상황을 어떻게 측정할 것인지 알고 나면 모델 개발을 시작할 수 있습니다. 대부분의 튜토리얼 및 연구 프로젝트는 이 단계가 유일한 단계라고 가정합니다. 즉, 이미 수행된 것으로 간주되는 문제 정의 및 데이터 집합은 건너뛰고, 다른 사용자가 처리하는 것으로 간주되는 모델 배치 및 유지보수는 건너뜁니다. 사실 모형 개발은 기계학습 워크플로우에서 한 단계일 뿐입니다.

### 데이터 준비하기
앞에서 배웠듯이 딥러닝 모델은 일반적으로 원시 데이터를 수집하지 않습니다. 데이터 전처리는 당면한 원시 데이터를 신경망에 더 잘 적응하도록 만드는 것을 목표로 합니다. 여기에는 벡터화, 정규화 또는 결측값 처리가 포함됩니다. 많은 사전 처리 기술은 도메인마다 다릅니다(예: 텍스트 데이터 또는 이미지 데이터). 아래에서 모든 데이터 도메인에 공통적으로 적용되는 기본 사항에 대해 살펴보겠습니다.

#### 백터화
신경망의 모든 입력과 대상은 일반적으로 부동 소수점 데이터(또는 특정한 경우 정수나 문자열의 텐서)의 텐서여야 합니다. 사운드, 이미지, 텍스트 등 처리해야 할 데이터가 무엇이든 먼저 텐서로 전환해야 하며, 이 단계를 **데이터 벡터화**라고 합니다

#### 정규화
데이터를 네트워크에 입력하기 전에 표준 편차가 1이고 평균이 0이 되도록 각 피쳐를 독립적으로 정규화하는 것을 말합니다.

#### 결측값 처리
때때로 데이터에 결측값이 있을 수 있습니다. 예를 들어, 주택(예: 가격)에서 첫 번째 특징(데이터의 지수 0 열)은 1인당 범죄율이었다. 만약 이 기능이 모든 샘플에서 사용할 수 없다면요? 그러면 교육 또는 검정 데이터에 결측값이 있게 됩니다. 이처럼 **모든 샘플에서 사용할 수 없는 것(한 샘플이라고 사용 불가)**을 결측값이라고 합니다.

### 평가 프로토콜 선택
모델의 목적은 일반화를 달성하는 것이며, 모델 개발 프로세스 전반에 걸쳐 내릴 모든 모델링 결정은 일반화 성과를 측정하기 위한 검증 지표에 의해 안내됩니다.

검증 프로토콜의 목표는 실제 프로덕션 데이터에서 선택한 성공 지표(예: 정확도)를 정확하게 추정하는 것입니다. 그 과정의 신뢰성은 유용한 모델을 구축하는 데 매우 중요합니다.

### 정해둔 정확도 넘기기
모형 자체에 대한 작업을 시작하면 통계적 검정력을 달성하는 것이 초기 목표입니다. 즉, 간단한 정확도를 능가할 수 있는 작은 모형을 개발하는 것입니다.

### 과대적합 발생시키기
일단 통계적 힘을 가진 모델을 얻으면, 질문은 여러분의 모델이 충분히 강력하냐는 것입니다. 그것은 당면한 문제를 적절하게 모델링하기에 충분한 레이어와 파라미터를 가지고 있는지를 물어보는 겁니다. 예를 들어, 로지스틱 회귀 분석 모형은 MNIST에 대한 통계적 검정력이 있지만 문제를 잘 해결하기에는 충분하지 않습니다. 머신러닝의 보편적인 장력은 최적화와 일반화 사이입니다. 이상적인 모델은 과소적합과 과적합, 과소용량과 과용량 사이의 경계에 서 있는 모델입니다. 이 경계가 어디에 있는지 알아내려면 먼저 경계를 넘어야 합니다.

### 모델 정규화 및 조정
일단 통계적 힘을 얻고 과대적합을 할 수 있게 되면, 여러분은 올바른 길을 가고 있다는 것을 알게 됩니다. 이때 일반화 성능을 최대화하는 것이 목표입니다.
이 단계에서는 모델이 최대한 좋은 결과를 얻을 때까지 반복적으로 모델을 수정하고 교육하고 검증 데이터(현 시점에서 테스트 데이터가 아님)를 평가한 다음 다시 수정하고 반복합니다.

## 모델 배포
귀하의 모델은 테스트에서 최종 평가를 성공적으로 통과했습니다.
세트—배포를 시작할 준비가 되었습니다.

### 이해 관계자에게 작업을 설명하고 기대치를 설정하기
성공과 고객 신뢰는 지속적으로 고객의 기대에 부응하거나 그 이상을 달성하는 것입니다. 실제로 제공하는 시스템은 그 그림의 절반에 불과합니다. 나머지 절반은 출시 전 적절한 기대치를 설정하고 있습니다.

AI 시스템에 대한 비전문가들의 기대는 종종 비현실적입니다. 예를 들어, 그들은 시스템이 과제를 "이해"하고 업무 맥락에서 상식과 같이 인간을 행사할 수 있다고 기대할 수 있습니다. 이 문제를 해결하려면 모형의 오류의 몇 가지 예제를 보여주는 것을 고려해야 합니다

또한 주요 시작 매개 변수(예: 트랜잭션에 플래그를 지정해야 하는 확률 임계값(임계값이 다르면 거짓 음수 및 거짓 긍정 비율이 다름)를 선택할 것인지 이해 관계자와 논의해야 합니다. 이러한 결정에는 비즈니스 맥락을 깊이 이해해야만 처리할 수 있는 트레이드오프가 포함됩니다.

### 임시 모형 전달
머신러닝 프로젝트는 훈련된 모델을 저장할 수 있는 colab 노트북에 도착해도 끝나지 않습니다. 교육 중에 조작한 것과 동일한 파이썬 모델 객체를 상품으로 넣는 경우는 거의 없습니다.

먼저 Python이 아닌 다른 것으로 모델을 내보내는 것이 좋습니다.

둘째, 프로덕션 모델은 교육을 위한 것이 아니라 예측(inJerence라고 하는 단계) 출력에만 사용되므로 모델을 더 빠르게 만들고 메모리 공간을 줄일 수 있는 다양한 최적화를 수행할 수 있습니다.

#### REST API로 모델 배포
이것은 아마도 모델을 제품으로 바꾸는 일반적인 방법일 것입니다.

REST API로 모델을 배포할 때 중요한 질문은 코드를 직접 호스팅할지 아니면 완전히 관리되는 타사 클라우드 서비스를 사용할지 여부입니다. 예를 들어 구글 제품인 클라우드 AI 플랫폼은 텐서플로우 모델을 구글 클라우드 스토리지(GCS)에 업로드하면 이를 쿼리할 수 있는 API 끝점을 제공한다. 일괄 처리 예측, 로드 밸런싱 및 확장과 같은 많은 실제적인 세부 사항을 처리합니다.

#### 모델을 장치에서 실행해보기
스마트폰, 로봇의 내장형 ARM CPU 또는 작은 장치의 마이크로컨트롤러 등 해당 애플리케이션을 실행하는 동일한 장치에 모델을 사용해야 하는 경우가 있습니다. 예를 들어, 여러분이 지목한 장면에서 사람과 얼굴을 자동으로 감지할 수 있는 카메라를 이미 본 적이 있을 것입니다.

#### 브라우저에서 실행해보기
딥 러닝은 브라우저 기반 또는 데스크톱 기반 자바스크립트 응용 프로그램에서 자주 사용됩니다. 응용 프로그램이 REST API를 통해 원격 모델을 쿼리하는 것이 보통 가능하지만 대신 사용자의 컴퓨터에서 직접 모델을 실행할 수 있는 주요 이점이 있을 수 있습니다.

####임시 모형 최적화
사용 가능한 전력 및 메모리(스마트폰 및 임베디드 장치)에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 추론을 위해 모델을 최적화하는 것이 특히 중요합니다. TensorFlow.js로 가져오거나 TensorFlow Lite로 내보내기 전에 항상 모델을 최적화해야 합니다.

### 모델 공개하기
추론 모델을 내보내고 이를 애플리케이션에 통합한 후 프로덕션 데이터에 대해 모의 실행을 수행했습니다. 이 모델은 예상대로 작동합니다. 유닛 테스트뿐만 아니라 로깅 및 상태 모니터링 코드도 작성했습니다. 이제 실운영에 투입할 차례입니다.

이것조차도 끝이 아닙니다. 모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 나머지 애플리케이션과의 상호 작용 및 궁극적으로 비즈니스 메트릭에 미치는 영향을 계속 모니터링해야 합니다.

### 모델 유지 관리
마지막으로, 영원한 모델은 없습니다. 컨셉 드리프트에 대해 이미 배웠습니다. 시간이 지남에 따라 생산 데이터의 특성이 바뀌어 모델의 성능과 관련성이 점차 저하됩니다.

모델이 출시되는 즉시 모델을 대체할 다음 세대를 준비를 해야 합니다.